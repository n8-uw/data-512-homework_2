{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering Bias in Data\n",
    "This notebook will explore the bias in Wikipedias page rating system. Using article data of various political leaders from all around the world, we query the [ORES system](https://ores.wikimedia.org/) in order to obtain rating estimates. \n",
    "\n",
    "## License\n",
    "This code example was developed by Nathan Grant for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided un\n",
    "der the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.0 - May 13, 2022\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# These are standard python modules\n",
    "import json, time, urllib.parse, os\n",
    "#\n",
    "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests\n",
    "# The 'pandas' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Shahjahan Noori</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Shahjahan_Noori</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Abdul Ghafar Lakanwal</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abdul_Ghafar_Lak...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                                url  \\\n",
       "0        Shahjahan Noori      https://en.wikipedia.org/wiki/Shahjahan_Noori   \n",
       "1  Abdul Ghafar Lakanwal  https://en.wikipedia.org/wiki/Abdul_Ghafar_Lak...   \n",
       "2         Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "3      Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "4            Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "\n",
       "       country  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle data inconsistencies in wikipedia data\n",
    "politicians_dataframe = pd.read_csv(os.getcwd()+ '\\\\data\\\\politicians_by_country_SEPT2022.csv')\n",
    "politicians_dataframe.head()\n",
    "# Removing region population values that have all caps, but save them for later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Torokul Dzhanuzakov              4\n",
       "Juraj Košút                      2\n",
       "Konstantin Jireček               2\n",
       "Antonio Gutiérrez y Ulloa        2\n",
       "Melko Čingrija                   2\n",
       "                                ..\n",
       "Clas Frietzcky                   1\n",
       "Thakur S. Powdyel                1\n",
       "Chang Sŏng-man                   1\n",
       "Kofi Batsa                       1\n",
       "David J. Francis (politician)    1\n",
       "Name: name, Length: 7534, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate records\n",
    "politicians_dataframe['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Population (millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>7963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Geography  Population (millions)\n",
       "0            WORLD                 7963.0\n",
       "1           AFRICA                 1419.0\n",
       "2  NORTHERN AFRICA                  251.0\n",
       "3          Algeria                   44.9\n",
       "4            Egypt                  103.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_dataframe = pd.read_csv(os.getcwd()+ '\\\\data\\\\population_by_country_2022.csv')\n",
    "population_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<uwnetid@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2022',\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "ARTICLE_TITLES = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    # Make sure we have an article title\n",
    "    if not article_title: return None\n",
    "    \n",
    "    request_template['titles'] = article_title\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page info data for:  Bison\n",
      "{\n",
      "    \"batchcomplete\": \"\",\n",
      "    \"query\": {\n",
      "        \"pages\": {\n",
      "            \"4583\": {\n",
      "                \"pageid\": 4583,\n",
      "                \"ns\": 0,\n",
      "                \"title\": \"Bison\",\n",
      "                \"contentmodel\": \"wikitext\",\n",
      "                \"pagelanguage\": \"en\",\n",
      "                \"pagelanguagehtmlcode\": \"en\",\n",
      "                \"pagelanguagedir\": \"ltr\",\n",
      "                \"touched\": \"2022-10-09T11:24:35Z\",\n",
      "                \"lastrevid\": 1115011990,\n",
      "                \"length\": 57004,\n",
      "                \"watchers\": 214,\n",
      "                \"talkid\": 75239,\n",
      "                \"fullurl\": \"https://en.wikipedia.org/wiki/Bison\",\n",
      "                \"editurl\": \"https://en.wikipedia.org/w/index.php?title=Bison&action=edit\",\n",
      "                \"canonicalurl\": \"https://en.wikipedia.org/wiki/Bison\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting page info data for: \",ARTICLE_TITLES[0])\n",
    "info = request_pageinfo_per_article(ARTICLE_TITLES[0])\n",
    "print(json.dumps(info,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Query for article scores\n",
    "\n",
    "# If an article cannot be resolved then list which ones cant be found\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
